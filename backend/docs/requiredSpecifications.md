# 要求仕様書: Voice Chat API

## 概要

本仕様書は、FastAPIを用いて開発されるリアルタイム音声対話バックエンドAPIの要求仕様を定義します。利用者はマイクを通じて音声で質問し、システムはLLM（大規模言語モデル）とTTS（Text-to-Speech）を用いて音声で応答します。最高のユーザー体験を提供することを目標とします。

## 機能要件

### 1. 基本的な音声対話機能

- WebSocket (`/ws/{client_id}`) を通じてクライアントと接続する。
- クライアントからの `"type": "start_recording"` メッセージ受信をトリガーとして、マイクからの音声入力を受け付ける。
- 受け付けた音声をテキストに変換する (Speech-to-Text)。
- 変換されたテキストに基づき、設定されたペルソナ（例: てぃ先生）として応答テキストを生成する (LLM)。
- 生成された応答テキストを音声に変換する (Text-to-Speech)。
- 変換された応答音声をWebSocketを通じてクライアントに送信する。
- 各クライアントの会話履歴をセッション内で保持する。
- 音声認識タイムアウト、認識失敗、APIエラー等の基本的なエラーハンドリングを行う。

### 2. デバッグ機能

- **デバッグモード:**
    - 環境変数 `DEBUG_MODE` (boolean, `true` or `false`) によってデバッグモードの有効/無効を切り替えられること。
    - デフォルトは無効 (`false`) とする。
- **音声ファイル保存:**
    - デバッグモードが有効 (`true`) の場合のみ、Speech-to-Text処理を行う **前** に受信した音声データをWAVファイルとして保存すること。
    - 保存場所は環境変数 `AUDIO_SAVE_PATH` (string, パス) で指定できること。
    - `AUDIO_SAVE_PATH` が指定されていない場合のデフォルトの保存場所は、プロジェクトルートから見て `../tmp` とすること。
    - 指定された保存ディレクトリが存在しない場合は、アプリケーションが自動的に作成すること。
    - 保存されるWAVファイル名は、`audio_<client_id>_<timestamp>.wav` の形式とし、クライアントIDとタイムスタンプ（ファイルが重複しない形式）を含むこと。
    - デバッグモードが無効 (`false`) の場合は、音声ファイルを一切保存しないこと。

### 3. 設定

- 各種APIキー (Google Gemini, OpenAI) は環境変数 (`GOOGLE_API_KEY`, `OPENAI_API_KEY`) から読み込むこと。
- LLMモデル設定 (モデル名、temperature等)、TTS設定 (モデル名、voice等)、音声認識設定 (言語、タイムアウト等) は設定ファイル (`app/core/config.py`) で管理し、必要に応じて環境変数からオーバーライド可能であること。

## 非機能要件

- **開発環境:** Macbook Air M3
- **プログラミング言語:** Python 3.10+
- **フレームワーク:** FastAPI
- **主要ライブラリ:** uvicorn, speechrecognition, google-generativeai, openai, python-dotenv, pyaudio, pydantic-settings
- **ディレクトリ構成:** 提供された技術制約の構成に従うこと。
- **コード品質:**
    - flake8規約に準拠すること。
    - Googleスタイル形式のPython Docstringを記述すること。
- **テスト:** pytestによる単体テスト・結合テストを実装し、主要な機能（特にデバッグモードの動作）をカバーすること。
- **データベース:** SQLite (ただし、現状の要求では未使用)
- **ドキュメンテーション:** 要求仕様書 (`docs/requiredSpecifications.md`) を更新すること。

## 将来的な拡張可能性 (考慮事項)
- データベースを用いた永続的な会話履歴の保存。
- 認証・認可機能の追加。
- より高度なエラーハンドリングとリトライロジック。
- WebRTC等を用いたより効率的な音声ストリーミング。
- Webフロントエンドとの連携。